## Problem Statement
Generative AI systems often produce confident but incorrect information, including hallucinated facts and fake or misquoted citations. Users currently lack a real-time system to verify AI-generated claims before trusting or using them, leading to misinformation, academic risks, and credibility issues.

## Project Name
TrustLayer AI â€“ Hallucination & Citation Verification System

## Team Name
Team-99

## Deployed Link (optional)
Not Deployed

## 2-minute Demonstration Video link
<ADD DEMO VIDEO LINK HERE>

## PPT Link
<ADD PPT LINK HERE>

---

## Project Overview
TrustLayer AI is a real-time verification platform designed to improve trust in AI-generated content. It analyzes AI responses at a claim level, verifies factual accuracy using trusted sources, checks citation authenticity, detects hallucinations, and generates an ove
